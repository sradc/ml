{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fashion MNIST example\n",
    "\n",
    "\"Hello world\" type example, based on https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from dotmap import DotMap\n",
    "from magic_timer import MagicTimer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 2.0.9\n",
      "torch 1.12.1\n",
      "torchvision 0.13.1\n",
      "tqdm 4.64.1\n"
     ]
    }
   ],
   "source": [
    "# print versions of imported libraries if can\n",
    "import sys\n",
    "\n",
    "for module_name in sorted(set(sys.modules) & set(globals())):\n",
    "    if version := getattr(sys.modules[module_name], \"__version__\", None):\n",
    "        print(module_name, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "get_timestamp = lambda: time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "start_time = get_timestamp()\n",
    "# Config and content to checkpoint (including models)\n",
    "cf = DotMap(\n",
    "    {\n",
    "        # training config\n",
    "        \"batch_size\": 64,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"num_epochs\": 10,\n",
    "        \"device\": device,\n",
    "        # meta config\n",
    "        \"ckpt_dir\": f\"data/PyTorch_Fashion_MNIST_example_ckpts/{start_time}\",\n",
    "        \"notebook_start_time\": start_time,\n",
    "        \"save_every_secs\": 30,\n",
    "        # active content\n",
    "        \"current_save_time\": None,\n",
    "        \"last_saved_time\": None,\n",
    "        \"model\": None,\n",
    "        \"optimizer\": None,\n",
    "        \"epoch_idx\": None,\n",
    "        \"batch_idx\": None,\n",
    "    }\n",
    ")\n",
    "# For append only data, use metrics\n",
    "metrics = DotMap(\n",
    "    {\n",
    "        \"train_loss_vals\": [],\n",
    "        \"test_loss_vals\": [],\n",
    "        \"test_accuracy_vals\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"batch_size\": 64,\n",
      "  \"learning_rate\": 0.001,\n",
      "  \"num_epochs\": 10,\n",
      "  \"device\": \"cuda\",\n",
      "  \"ckpt_dir\": \"data/PyTorch_Fashion_MNIST_example_ckpts/20220919-192333\",\n",
      "  \"notebook_start_time\": \"20220919-192333\",\n",
      "  \"save_every_secs\": 30,\n",
      "  \"last_saved_time\": null,\n",
      "  \"model\": null,\n",
      "  \"optimizer\": null,\n",
      "  \"epoch_idx\": null,\n",
      "  \"batch_idx\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class ConfigEncoder(json.JSONEncoder):\n",
    "    \"Handle things in `cf` that Pickle can't dump.\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, nn.Module):\n",
    "            return str(obj)\n",
    "        elif isinstance(obj, torch.optim.Optimizer):\n",
    "            return str(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "print(json.dumps(cf.toDict(), cls=ConfigEncoder, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    \"Save model, config, metrics, plots.\"\n",
    "    cf.current_save_time = time.time()\n",
    "    ts = get_timestamp()\n",
    "    Path(cf.ckpt_dir).mkdir(exist_ok=True, parents=True)\n",
    "    with open(f\"{cf.ckpt_dir}/{ts}.pickle\", \"wb\") as f:\n",
    "        pickle.dump(cf, f)\n",
    "    with open(f\"{cf.ckpt_dir}/{ts}.json\", \"w\") as f:\n",
    "        json.dump(cf.toDict(), fp=f, cls=ConfigEncoder, indent=2)\n",
    "    # update the metrics file\n",
    "    with open(f\"{cf.ckpt_dir}/metrics.json\", \"w\") as f:\n",
    "        json.dump(metrics.toDict(), fp=f, indent=2)\n",
    "    # handy plots to look at\n",
    "    if metrics.train_loss_vals:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "        plt.plot(metrics.train_loss_vals)\n",
    "        plt.title(\"Train loss vals\")\n",
    "        plt.savefig(f\"{cf.ckpt_dir}/train_loss_vals.png\")\n",
    "        plt.close(fig)\n",
    "    if metrics.test_loss_vals:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "        plt.plot(metrics.test_loss_vals)\n",
    "        plt.title(\"Test loss vals\")\n",
    "        plt.savefig(f\"{cf.ckpt_dir}/test_loss_vals.png\")\n",
    "        plt.close(fig)\n",
    "    if metrics.test_accuracy_vals:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "        plt.plot(metrics.test_accuracy_vals)\n",
    "        plt.title(\"Test accuracy vals\")\n",
    "        plt.savefig(f\"{cf.ckpt_dir}/test_accuracy_vals.png\")\n",
    "        plt.close(fig)\n",
    "    cf.last_saved_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "test_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True, transform=torchvision.transforms.ToTensor()\n",
    ")\n",
    "train_dataloader = DataLoader(training_data, batch_size=cf.batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=cf.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, epoch):\n",
    "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch}\")\n",
    "    for batch_idx, (X, y) in enumerate(pbar):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "        # Keep track of these globally\n",
    "        cf.epoch_idx = epoch\n",
    "        cf.batch_idx = batch_idx\n",
    "        metrics.train_loss_vals.append(loss.item())\n",
    "        if time.time() - cf.last_saved_time > cf.save_every_secs:\n",
    "            print(\"Saving model.\")\n",
    "            save()\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    metrics.test_loss_vals.append(test_loss)\n",
    "    metrics.test_accuracy_vals.append(correct)\n",
    "    print(f\"Test set: Accuracy = {(100*correct):.1f}%, Mean loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 938/938 [00:09<00:00, 95.09it/s, loss=2.1290] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 46.9%, Mean loss = 2.1384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 938/938 [00:09<00:00, 101.14it/s, loss=1.8551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 54.2%, Mean loss = 1.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  98%|█████████▊| 917/938 [00:09<00:00, 106.74it/s, loss=1.4938]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 938/938 [00:09<00:00, 98.45it/s, loss=1.5094] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 59.5%, Mean loss = 1.4759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 938/938 [00:09<00:00, 101.32it/s, loss=1.2656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 63.1%, Mean loss = 1.2287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 938/938 [00:09<00:00, 103.30it/s, loss=1.1194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 64.9%, Mean loss = 1.0753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  96%|█████████▌| 897/938 [00:08<00:00, 97.09it/s, loss=0.8532] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 938/938 [00:09<00:00, 97.74it/s, loss=1.0247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 66.3%, Mean loss = 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 938/938 [00:09<00:00, 100.57it/s, loss=0.9583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 67.3%, Mean loss = 0.9056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 938/938 [00:09<00:00, 102.44it/s, loss=0.9090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 68.3%, Mean loss = 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:  93%|█████████▎| 877/938 [00:08<00:00, 102.82it/s, loss=0.7642]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 938/938 [00:09<00:00, 100.51it/s, loss=0.8711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 69.6%, Mean loss = 0.8156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 938/938 [00:09<00:00, 102.25it/s, loss=0.8404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy = 71.2%, Mean loss = 0.7839\n",
      "Trained model in 1.8 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train for `cf.num_epochs` epochs\n",
    "timer = MagicTimer()\n",
    "model = Model().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=cf.learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "# Checkpoint these\n",
    "cf.model = model\n",
    "cf.optimizer = optimizer\n",
    "# Save the initial model\n",
    "save()\n",
    "for i in range(1, cf.num_epochs + 1):\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer, epoch=i)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "save()\n",
    "print(f\"Trained model in {timer}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe5aee2b7a92942ddc0f3d81b8f1c9d7e2f7b0dccf0c1fb5bc9d004c3b1b35d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
